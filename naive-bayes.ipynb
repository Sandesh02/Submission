{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1><center>Naive Bayes</center></h1>\n\n#### What are Bayesian Networks?\n* In general, Bayesian Networks (BNs) is a framework for reasoning under uncertainty using probabilities. More formally, a BN is defined as a Directed Acyclic Graph (DAG) and a set of Conditional Probability Tables (CPTs). In practice, a problem domain is initially modeled as a DAG.\n* Naive Bayes assumes that the variables are independent and comes from a Gaussian distribution.\n\n#### The Bayes theorem\n<img src=\"https://i0.wp.com/scienceprog.com/wp-content/uploads/2016/07/Thomas_Bayes.png?fit=468%2C308&ssl=1\" width=\"400\">\n* P(A|B) is the posterior probability of class (A, target) given predictor (B,  attributes).\n* P(A) is the prior probability of class.\n* P(B|A) is the likelihood which is the probability of predictor given class.\n* P(B) is the prior probability of predictor.\n\n### Now let's apply this knowledge by building a Naive Bayes model on this data set.","metadata":{"_uuid":"eef89fc84ffbec0aa8eb3acfbabd73c917e7dd3c"}},{"cell_type":"markdown","source":"### Dependencies","metadata":{"_uuid":"78b6b671013de316d0f069feefc7ff889e6451e5"}},{"cell_type":"code","source":"import warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats.stats import pearsonr\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score\n\n%matplotlib inline\n# Suppress warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-24T12:00:27.717645Z","iopub.execute_input":"2022-05-24T12:00:27.718002Z","iopub.status.idle":"2022-05-24T12:00:27.727631Z","shell.execute_reply.started":"2022-05-24T12:00:27.717949Z","shell.execute_reply":"2022-05-24T12:00:27.726830Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### Auxiliary functions","metadata":{"_uuid":"6f4f3f688a851ac4c8875a8b5edf54fcd731284e"}},{"cell_type":"code","source":"def cross_validate(estimator, train, validation):\n    X_train = train[0]\n    Y_train = train[1]\n    X_val = validation[0]\n    Y_val = validation[1]\n    train_predictions = classifier.predict(X_train)\n    train_accuracy = accuracy_score(train_predictions, Y_train)\n    train_recall = recall_score(train_predictions, Y_train)\n    train_precision = precision_score(train_predictions, Y_train)\n\n    val_predictions = classifier.predict(X_val)\n    val_accuracy = accuracy_score(val_predictions, Y_val)\n    val_recall = recall_score(val_predictions, Y_val)\n    val_precision = precision_score(val_predictions, Y_val)\n\n    print('Model metrics')\n    print('Accuracy  Train: %.2f, Validation: %.2f' % (train_accuracy, val_accuracy))\n    print('Recall    Train: %.2f, Validation: %.2f' % (train_recall, val_recall))\n    print('Precision Train: %.2f, Validation: %.2f' % (train_precision, val_precision))","metadata":{"_kg_hide-input":true,"_uuid":"d6f043ecd7bbfb5c874aed6f128b915d3ffdb0a0","execution":{"iopub.status.busy":"2022-05-24T12:00:27.729061Z","iopub.execute_input":"2022-05-24T12:00:27.729425Z","iopub.status.idle":"2022-05-24T12:00:27.740472Z","shell.execute_reply.started":"2022-05-24T12:00:27.729260Z","shell.execute_reply":"2022-05-24T12:00:27.739572Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### Load data","metadata":{"_uuid":"69863afcf2938c019b9025f4aa7dcafdad7bae03"}},{"cell_type":"code","source":"train_raw = pd.read_csv('../input/train.csv')\ntest_raw = pd.read_csv('../input/test.csv')\ntest_ids = test_raw['PassengerId'].values\n\n# Join data to analyse and process the set as one.\ntrain_raw['train'] = 1\ntest_raw['train'] = 0\ndata = train_raw.append(test_raw, sort=False)","metadata":{"_uuid":"58307dcedd682f2353681fb1fb724aa059271605","_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-05-24T12:00:27.742777Z","iopub.execute_input":"2022-05-24T12:00:27.743286Z","iopub.status.idle":"2022-05-24T12:00:27.775742Z","shell.execute_reply.started":"2022-05-24T12:00:27.743066Z","shell.execute_reply":"2022-05-24T12:00:27.775019Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"### Overview the data","metadata":{"_uuid":"fa61280471a2e54b91d63c03ba42e6d20e7ca55b"}},{"cell_type":"code","source":"data.head()","metadata":{"_uuid":"17e2647441b6365242283a3ed718fe355d10429b","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-24T12:00:27.777066Z","iopub.execute_input":"2022-05-24T12:00:27.777470Z","iopub.status.idle":"2022-05-24T12:00:27.807624Z","shell.execute_reply.started":"2022-05-24T12:00:27.777428Z","shell.execute_reply":"2022-05-24T12:00:27.806759Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"_uuid":"020c32baeb833a88b486e9151da3305eca9354fd","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-24T12:00:27.808555Z","iopub.execute_input":"2022-05-24T12:00:27.808837Z","iopub.status.idle":"2022-05-24T12:00:27.853875Z","shell.execute_reply.started":"2022-05-24T12:00:27.808787Z","shell.execute_reply":"2022-05-24T12:00:27.852795Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"One advantage of Bayesian models is that it works well enough with small data, having more would give you more accurate probabilities but it's not data hungry as something like deep learning.\n\n### Pre-process\n* feature selection, data cleaning, feature engineering and data imputation","metadata":{"_uuid":"bffc61a690870527eb34aa8c19ef31928358476b"}},{"cell_type":"code","source":"features = ['Age', 'Embarked', 'Fare', 'Parch', 'Pclass', 'Sex', 'SibSp']\ntarget = 'Survived'\n\ndata = data[features + [target] + ['train']]\n# Categorical values need to be transformed into numeric.\ndata['Sex'] = data['Sex'].replace([\"female\", \"male\"], [0, 1])\ndata['Embarked'] = data['Embarked'].replace(['S', 'C', 'Q'], [1, 2, 3])\ndata['Age'] = pd.qcut(data['Age'], 10, labels=False)","metadata":{"_uuid":"acbdfcabff5a80d326615e42629f3bbd8c84edbe","execution":{"iopub.status.busy":"2022-05-24T12:00:27.857089Z","iopub.execute_input":"2022-05-24T12:00:27.857590Z","iopub.status.idle":"2022-05-24T12:00:27.957063Z","shell.execute_reply.started":"2022-05-24T12:00:27.857397Z","shell.execute_reply":"2022-05-24T12:00:27.956160Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Split data into train and test.\ntrain = data.query('train == 1')\ntest = data.query('train == 0')\n\n# Drop missing values from the train set.\ntrain.dropna(axis=0, inplace=True)\nlabels = train[target].values","metadata":{"_uuid":"96b9f5730cd6c5e21e96567252b98ff81eb5ab54","_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-05-24T12:00:27.959213Z","iopub.execute_input":"2022-05-24T12:00:27.959473Z","iopub.status.idle":"2022-05-24T12:00:28.054608Z","shell.execute_reply.started":"2022-05-24T12:00:27.959425Z","shell.execute_reply":"2022-05-24T12:00:28.053794Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"Our processed train set","metadata":{"_uuid":"3ab1d08c7de6c5c6d939c15e43066da44589950b"}},{"cell_type":"code","source":"train.head()","metadata":{"_uuid":"0701969fc0bbe441860961dfe53326e3e4430897","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-24T12:00:28.055526Z","iopub.execute_input":"2022-05-24T12:00:28.055812Z","iopub.status.idle":"2022-05-24T12:00:28.076871Z","shell.execute_reply.started":"2022-05-24T12:00:28.055757Z","shell.execute_reply":"2022-05-24T12:00:28.076033Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"### Correlation study\n* As we saw Naive Bayes models expect the features to be independent, so let's apply the Pearson correlation coefficient on them to give us a hint about how independent they are from the others.","metadata":{"_uuid":"b9f1ee0bb0675876d1b3b13c7aeb966228b92160"}},{"cell_type":"code","source":"columns = train[features + [target]].columns.tolist()\nnColumns = len(columns)\nresult = pd.DataFrame(np.zeros((nColumns, nColumns)), columns=columns)\n\n# Apply Pearson correlation on each pair of features.\nfor col_a in range(nColumns):\n    for col_b in range(nColumns):\n        result.iloc[[col_a], [col_b]] = pearsonr(train.loc[:, columns[col_a]], train.loc[:,  columns[col_b]])[0]\n        \nfig, ax = plt.subplots(figsize=(10,10))\nax = sns.heatmap(result, yticklabels=columns, vmin=-1, vmax=1, annot=True, fmt='.2f', linewidths=.2)\nax.set_title('PCC - Pearson correlation coefficient')\nplt.show()","metadata":{"_uuid":"c0ab48f4472c0fb34692abac3880404207989d7e","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-24T12:00:28.077935Z","iopub.execute_input":"2022-05-24T12:00:28.078173Z","iopub.status.idle":"2022-05-24T12:00:28.780573Z","shell.execute_reply.started":"2022-05-24T12:00:28.078128Z","shell.execute_reply":"2022-05-24T12:00:28.779581Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"About the correlation between the features, we can see that \"Fare\" and \"Pclass\" seem to be highly related, so i'll remove \"Pclass\". Also features like \"Sex\", \"Pclass\" and \"Fare\" should be good predictors.\n\n### Distribution study\n* Also the model expect the features to come from a Gaussian (or normal) distribution, so let's check that as well.","metadata":{"_uuid":"047a8fb7db2b58efdaa61c7fe11dd86f2ffa2187"}},{"cell_type":"code","source":"continuous_numeric_features = ['Age', 'Fare', 'Parch', 'SibSp']\nfor feature in continuous_numeric_features:\n    sns.distplot(train[feature])\n    plt.show()","metadata":{"_uuid":"bfbe5de3e2ab921f7df8752e16756d63e7ec0047","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-24T12:00:28.782441Z","iopub.execute_input":"2022-05-24T12:00:28.783089Z","iopub.status.idle":"2022-05-24T12:00:29.775899Z","shell.execute_reply.started":"2022-05-24T12:00:28.783014Z","shell.execute_reply":"2022-05-24T12:00:29.774500Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"Looking at our continuous numeric features we can see that \"Fare\", \"Parch\" and \"SibSp\", have a distribution close to normal, but with a left side skew, \"Age\" have a distribution a a bit different from the other but maybe it's close enough to Gaussian.","metadata":{"_uuid":"2d9cb0c7c06827d7324b153426c955a68e60294e"}},{"cell_type":"code","source":"train.drop(['train', target, 'Pclass'], axis=1, inplace=True)\ntest.drop(['train', target, 'Pclass'], axis=1, inplace=True)","metadata":{"_uuid":"bfb14dfc915c90e09870f4ca14c0b3f8806e7446","_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-05-24T12:00:29.777523Z","iopub.execute_input":"2022-05-24T12:00:29.778241Z","iopub.status.idle":"2022-05-24T12:00:29.982757Z","shell.execute_reply.started":"2022-05-24T12:00:29.778127Z","shell.execute_reply":"2022-05-24T12:00:29.981489Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"### Split data in train and validation (80% ~ 20%)","metadata":{"_kg_hide-input":false,"_uuid":"92235de1df681e329f1e70527abca5cfdb9cdb4d"}},{"cell_type":"code","source":"X_train, X_val, Y_train, Y_val = train_test_split(train, labels, test_size=0.2, random_state=1)","metadata":{"_uuid":"2c7b37d4af8a07a1bc448fff1aa9252c398d88b1","execution":{"iopub.status.busy":"2022-05-24T12:00:29.983840Z","iopub.execute_input":"2022-05-24T12:00:29.984087Z","iopub.status.idle":"2022-05-24T12:00:29.995014Z","shell.execute_reply.started":"2022-05-24T12:00:29.984041Z","shell.execute_reply":"2022-05-24T12:00:29.993973Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"_uuid":"96ee31cb80df049d40daa7708450f3499e0f3204","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-24T12:00:29.996045Z","iopub.execute_input":"2022-05-24T12:00:29.996310Z","iopub.status.idle":"2022-05-24T12:00:30.018996Z","shell.execute_reply.started":"2022-05-24T12:00:29.996262Z","shell.execute_reply":"2022-05-24T12:00:30.018302Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"### Split train data into two parts","metadata":{"_uuid":"38ff354d30c45580677cd35d21aad7b015a6c3e1"}},{"cell_type":"code","source":"X_train1, X_train2, Y_train1, Y_train2 = train_test_split(X_train, Y_train, test_size=0.3, random_state=12)","metadata":{"_uuid":"0c709e510191b63562407a2b23401c63508bad83","execution":{"iopub.status.busy":"2022-05-24T12:00:30.020003Z","iopub.execute_input":"2022-05-24T12:00:30.020430Z","iopub.status.idle":"2022-05-24T12:00:30.026414Z","shell.execute_reply.started":"2022-05-24T12:00:30.020388Z","shell.execute_reply":"2022-05-24T12:00:30.025513Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"### Naive Bayes classifier\n\n#### This image may help to understand how a simple Bayesian model works.\n![Example of Bayes theorem aplication](http://users.sussex.ac.uk/~christ/crs/kr-ist/copied-pics/humidity-bayesian-network.png)\n* Given that we have sun, rain and temperature events and we want to predict if will be humid or not, the probability of being humid will be calculated from the other given events ant theirs probabilities.\n* In the boxes we have \"sun\" as a independent event, \"rain\" and \"temp\" as events that depends from \"sun\" and finally \"humid\" that depends from all the other.\n* In the lower right text, we have the probability of \"humid\" being yes or no given that \"sun\" = yes (sun = 100%), so given that is sunny we have 46% probability of being humid and 54% probability of not being humid.\n\n#### How Naive Bayes algorithm works?\n* Convert the data set into a frequency table\n* Create Likelihood table by finding the probabilities.\n* Now, use Naive Bayesian equation to calculate the posterior probability for each class. The class with the highest posterior probability is the outcome of prediction.\n\n\n##### As you can see the whole model is built upon the probabilities of events, that would be our features.","metadata":{"_uuid":"9bbf5e144da872cc49eb154b86a100d6c22bf58e","trusted":true}},{"cell_type":"code","source":"classifier = GaussianNB()","metadata":{"_uuid":"ff22e878edf3d99d7ff272aa9653b36140505da1","execution":{"iopub.status.busy":"2022-05-24T12:00:30.030816Z","iopub.execute_input":"2022-05-24T12:00:30.031173Z","iopub.status.idle":"2022-05-24T12:00:30.041181Z","shell.execute_reply.started":"2022-05-24T12:00:30.031100Z","shell.execute_reply":"2022-05-24T12:00:30.040304Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"#### Fit the first part\n* Fitting data here is really fast.","metadata":{"_uuid":"d62839bd20993df42c2b1fffd2ddddcb24da7731"}},{"cell_type":"code","source":"classifier.fit(X_train2, Y_train2)","metadata":{"_uuid":"cef67c99c01a6b83caa7b9861c2603dafa2619f2","execution":{"iopub.status.busy":"2022-05-24T12:00:30.044397Z","iopub.execute_input":"2022-05-24T12:00:30.044755Z","iopub.status.idle":"2022-05-24T12:00:30.054829Z","shell.execute_reply.started":"2022-05-24T12:00:30.044700Z","shell.execute_reply":"2022-05-24T12:00:30.054195Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"print('Metrics with only 30% of train data')\ncross_validate(classifier, (X_train, Y_train), (X_val, Y_val))","metadata":{"_uuid":"0c729862f56c1201042e4899700d7ee9196abb03","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-24T12:00:30.055743Z","iopub.execute_input":"2022-05-24T12:00:30.056130Z","iopub.status.idle":"2022-05-24T12:00:30.068792Z","shell.execute_reply.started":"2022-05-24T12:00:30.055921Z","shell.execute_reply":"2022-05-24T12:00:30.068050Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"#### Update the model with the second part\n* Nice thing about this kind of model, you can update it by just fitting the model again with more data.","metadata":{"_uuid":"40f3ecb8b8d66be494d3d33a88a44658afefa46c"}},{"cell_type":"code","source":"classifier.partial_fit(X_train1, Y_train1)","metadata":{"_uuid":"dcad148d72770b44b05c2d3e34cc134ccda1b958","execution":{"iopub.status.busy":"2022-05-24T12:00:30.069799Z","iopub.execute_input":"2022-05-24T12:00:30.070063Z","iopub.status.idle":"2022-05-24T12:00:30.080462Z","shell.execute_reply.started":"2022-05-24T12:00:30.070012Z","shell.execute_reply":"2022-05-24T12:00:30.079702Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"print('Metrics with the remaining 70% of train data')\ncross_validate(classifier, (X_train, Y_train), (X_val, Y_val))","metadata":{"_uuid":"717d0760281c0f8ab51e22c6b880d0069c6a39ae","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-24T12:00:30.082959Z","iopub.execute_input":"2022-05-24T12:00:30.083343Z","iopub.status.idle":"2022-05-24T12:00:30.094300Z","shell.execute_reply.started":"2022-05-24T12:00:30.083182Z","shell.execute_reply":"2022-05-24T12:00:30.093729Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"As you can see our results improved after we updated  the model with the remaining data.\n\nThe sklearn model also give us some interesting options from the model API about the target class.","metadata":{"_uuid":"0126f37767fbe291f20a5ebf965353fedacfcf17"}},{"cell_type":"code","source":"print('Probability of each class')\nprint('Survive = 0: %.2f' % classifier.class_prior_[0])\nprint('Survive = 1: %.2f' % classifier.class_prior_[1])","metadata":{"_kg_hide-input":true,"_uuid":"8d6d05d83697544629765faf91211c85d1c7c839","execution":{"iopub.status.busy":"2022-05-24T12:00:30.095319Z","iopub.execute_input":"2022-05-24T12:00:30.095735Z","iopub.status.idle":"2022-05-24T12:00:30.101858Z","shell.execute_reply.started":"2022-05-24T12:00:30.095690Z","shell.execute_reply":"2022-05-24T12:00:30.101280Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"print('Mean of each feature per class')\nprint('               Age         Embarked   Fare         Parch       Sex         SibSp')\nprint('Survive = 0: %s' % classifier.theta_[0])\nprint('Survive = 1: %s' % classifier.theta_[1])","metadata":{"_kg_hide-input":true,"_uuid":"e89e0ee92e19686d25906bd677f73e8d88f304c5","execution":{"iopub.status.busy":"2022-05-24T12:00:30.102939Z","iopub.execute_input":"2022-05-24T12:00:30.103530Z","iopub.status.idle":"2022-05-24T12:00:30.115572Z","shell.execute_reply.started":"2022-05-24T12:00:30.103487Z","shell.execute_reply":"2022-05-24T12:00:30.114748Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"print('Variance of each feature per class')\nprint('Survive = 0: %s' % classifier.sigma_[0])\nprint('Survive = 1: %s' % classifier.sigma_[1])","metadata":{"_kg_hide-input":true,"_uuid":"b25337bf9fbb2433da6d385849dac53ac295bb4a","execution":{"iopub.status.busy":"2022-05-24T12:00:30.116748Z","iopub.execute_input":"2022-05-24T12:00:30.116976Z","iopub.status.idle":"2022-05-24T12:00:30.126076Z","shell.execute_reply.started":"2022-05-24T12:00:30.116934Z","shell.execute_reply":"2022-05-24T12:00:30.125480Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"### Apply the model on the test data and create submission","metadata":{"_uuid":"704dcce51b9a7d5052dba8c99fd75b6c1d7c5868"}},{"cell_type":"code","source":"# Unfortunately sklearn naive Bayes algorithm currently do not make inference with missing data (but should do), so we need to input missing data.\ntest.fillna(test.mean(), inplace=True)\ntest_predictions = classifier.predict(test)\nsubmission = pd.DataFrame({'PassengerId': test_ids})\nsubmission['Survived'] = test_predictions.astype('int')\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head(10)","metadata":{"_uuid":"f53ad1e46f92415bd2a28ac157785f0baf631d4e","execution":{"iopub.status.busy":"2022-05-24T12:00:38.416217Z","iopub.execute_input":"2022-05-24T12:00:38.416537Z","iopub.status.idle":"2022-05-24T12:00:38.908007Z","shell.execute_reply.started":"2022-05-24T12:00:38.416482Z","shell.execute_reply":"2022-05-24T12:00:38.907110Z"},"trusted":true},"execution_count":47,"outputs":[]}]}