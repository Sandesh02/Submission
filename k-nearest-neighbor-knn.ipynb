{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### k-nearest-neighbor (KNN) \nK-Nearest Neighbors is a simple but important classification technique in machine learning. It's a supervised learning algorithm which is used a lot in pattern recognition, data mining, and intrusion detection.\n\nIt is entirely applicable in realistic conditions since it is non-parametric, which implies it makes no underlying assumptions about data distribution (unlike other algorithms like GMM, which require a Gaussian distribution of the input data).\n\nPrior data (also known as training data) is provided, which divides coordinates into groups based on an attribute.\n\n### Content\n1. Data preparation\n2. Create additional features\n3. Algorithm creation\n4. Test algorithm\n5. Create test predictions","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:29.096693Z","iopub.execute_input":"2022-05-24T11:24:29.097089Z","iopub.status.idle":"2022-05-24T11:24:30.182601Z","shell.execute_reply.started":"2022-05-24T11:24:29.097047Z","shell.execute_reply":"2022-05-24T11:24:30.181330Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# 1. Data preparation","metadata":{}},{"cell_type":"markdown","source":"First lets import the data and generate one set to process all data at once","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/titanic/train.csv')\ntest = pd.read_csv('../input/titanic/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:30.185617Z","iopub.execute_input":"2022-05-24T11:24:30.186123Z","iopub.status.idle":"2022-05-24T11:24:30.215055Z","shell.execute_reply.started":"2022-05-24T11:24:30.186075Z","shell.execute_reply":"2022-05-24T11:24:30.213924Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train['set'], test['set'] = 'train', 'test'\ncombined = pd.concat([train, test])","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:30.216567Z","iopub.execute_input":"2022-05-24T11:24:30.216997Z","iopub.status.idle":"2022-05-24T11:24:30.237859Z","shell.execute_reply.started":"2022-05-24T11:24:30.216932Z","shell.execute_reply":"2022-05-24T11:24:30.236687Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Missing values\n#### First step is to fill missing values and drop columns we will not be using.","metadata":{}},{"cell_type":"code","source":"combined.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:30.239605Z","iopub.execute_input":"2022-05-24T11:24:30.240434Z","iopub.status.idle":"2022-05-24T11:24:30.266179Z","shell.execute_reply.started":"2022-05-24T11:24:30.240382Z","shell.execute_reply":"2022-05-24T11:24:30.265112Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"#### Only one Fare price is missing. fill it with the median of his Pclass:","metadata":{}},{"cell_type":"code","source":"pclass = combined.loc[combined.Fare.isnull(), 'Pclass'].values[0]\nmedian_fare = combined.loc[combined.Pclass== pclass, 'Fare'].median()\ncombined.loc[combined.Fare.isnull(), 'Fare'] = median_fare","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:30.283203Z","iopub.execute_input":"2022-05-24T11:24:30.283900Z","iopub.status.idle":"2022-05-24T11:24:30.320698Z","shell.execute_reply.started":"2022-05-24T11:24:30.283848Z","shell.execute_reply":"2022-05-24T11:24:30.319455Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"#### Missing ages\nTo fill in the missing ages, we can do something more clever then just take the overal median age. The names contain titles of which some are linked to their age. Master is a younger boy (in general). Lets take the median of each age group.","metadata":{}},{"cell_type":"code","source":"# Select everything before the . as title\ncombined['Title'] = combined['Name'].str.extract('([A-Za-z]+)\\.', expand=True)\ncombined['Title'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:30.322225Z","iopub.execute_input":"2022-05-24T11:24:30.322874Z","iopub.status.idle":"2022-05-24T11:24:30.343765Z","shell.execute_reply.started":"2022-05-24T11:24:30.322827Z","shell.execute_reply":"2022-05-24T11:24:30.342286Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"title_reduction = {'Mr': 'Mr', 'Mrs': 'Mrs', 'Miss': 'Miss', \n                   'Master': 'Master', 'Don': 'Mr', 'Rev': 'Rev',\n                   'Dr': 'Dr', 'Mme': 'Miss', 'Ms': 'Miss',\n                   'Major': 'Mr', 'Lady': 'Mrs', 'Sir': 'Mr',\n                   'Mlle': 'Miss', 'Col': 'Mr', 'Capt': 'Mr',\n                   'Countess': 'Mrs','Jonkheer': 'Mr',\n                   'Dona': 'Mrs'}\ncombined['Title'] = combined['Title'].map(title_reduction)\ncombined['Title'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:30.345346Z","iopub.execute_input":"2022-05-24T11:24:30.346058Z","iopub.status.idle":"2022-05-24T11:24:30.359983Z","shell.execute_reply.started":"2022-05-24T11:24:30.346006Z","shell.execute_reply":"2022-05-24T11:24:30.358871Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"for title, age in combined.groupby('Title')['Age'].median().iteritems():\n    print(title, age)\n    combined.loc[(combined['Title']==title) & (combined['Age'].isnull()), 'Age'] = age","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:30.361472Z","iopub.execute_input":"2022-05-24T11:24:30.361833Z","iopub.status.idle":"2022-05-24T11:24:30.391318Z","shell.execute_reply.started":"2022-05-24T11:24:30.361801Z","shell.execute_reply":"2022-05-24T11:24:30.390248Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"combined.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:30.392647Z","iopub.execute_input":"2022-05-24T11:24:30.393091Z","iopub.status.idle":"2022-05-24T11:24:30.403755Z","shell.execute_reply.started":"2022-05-24T11:24:30.393056Z","shell.execute_reply":"2022-05-24T11:24:30.402549Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# 2. Create additional features","metadata":{}},{"cell_type":"code","source":"def other_family_members_survived(dataset, label='family_survival'):\n    \"\"\"\n    Check if other family members survived\n      -> 0 other did not survive\n      -> 1 at least one other family member survived\n      -> 0.5 unknown if other members survived or person was alone\n    \n    Parameters\n    ----------\n    dataset : DataFrame\n      The sub-dataframe containing the family\n    \"\"\"\n    ds = dataset.copy()\n    if len(dataset) == 1:\n        ds[label] = 0.5\n        return ds\n    result = []\n    for ix, row in dataset.iterrows():\n        survived_fraction = dataset.drop(ix)['Survived'].mean()\n        if np.isnan(survived_fraction):\n            result.append(0.5)\n        elif survived_fraction == 0:\n            result.append(0)\n        else:\n            result.append(1)\n    ds[label] = result\n    return ds","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:30.405426Z","iopub.execute_input":"2022-05-24T11:24:30.405791Z","iopub.status.idle":"2022-05-24T11:24:30.416909Z","shell.execute_reply.started":"2022-05-24T11:24:30.405760Z","shell.execute_reply":"2022-05-24T11:24:30.415741Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"combined['surname'] = combined['Name'].apply(lambda x: x.split(\",\")[0])\ncombined = combined.groupby(['surname', 'Fare']).apply(other_family_members_survived).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:30.419001Z","iopub.execute_input":"2022-05-24T11:24:30.419467Z","iopub.status.idle":"2022-05-24T11:24:33.327592Z","shell.execute_reply.started":"2022-05-24T11:24:30.419420Z","shell.execute_reply":"2022-05-24T11:24:33.326719Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Missing data on families can also be extracted from Tickets. Same ticket orders have the same ticket number.","metadata":{}},{"cell_type":"code","source":"combined = combined.groupby(['Ticket']).apply(lambda x: other_family_members_survived(x, label='family_survival_ticket')).reset_index(drop=True)\ncombined.loc[combined['family_survival'] == 0.5, 'family_survival'] = combined.loc[combined['family_survival'] == 0.5, 'family_survival_ticket']","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:33.328757Z","iopub.execute_input":"2022-05-24T11:24:33.329224Z","iopub.status.idle":"2022-05-24T11:24:36.314395Z","shell.execute_reply.started":"2022-05-24T11:24:33.329168Z","shell.execute_reply":"2022-05-24T11:24:36.313253Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Get family size from Parch and Sibsp","metadata":{}},{"cell_type":"code","source":"combined['family_size'] = combined['Parch'] + combined['SibSp']","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:36.315732Z","iopub.execute_input":"2022-05-24T11:24:36.316061Z","iopub.status.idle":"2022-05-24T11:24:36.322269Z","shell.execute_reply.started":"2022-05-24T11:24:36.316028Z","shell.execute_reply":"2022-05-24T11:24:36.321207Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"KNN needs numerical features therefore, we will convert them to numbers. In a general sense, binary categorical data can work. For larger categorical groups, it only makes sense when the numerical values itself have meaning. For example, for class levels, the difference between first class and third class actually mean something. On the other hand, if we would convert Embarked to a number, there is no meaning in the difference between embarked 1 and embarked 2.","metadata":{}},{"cell_type":"code","source":"combined['Sex'] = LabelEncoder().fit_transform(combined['Sex'])","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:36.323704Z","iopub.execute_input":"2022-05-24T11:24:36.324084Z","iopub.status.idle":"2022-05-24T11:24:36.343700Z","shell.execute_reply.started":"2022-05-24T11:24:36.324049Z","shell.execute_reply":"2022-05-24T11:24:36.342494Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"First bin the Fare and Age. The groups are choosen arbitrarily:","metadata":{}},{"cell_type":"code","source":"combined.loc[:, 'Age'] = pd.qcut(combined['Age'], 4, labels=False)\ncombined.loc[:, 'Fare'] = pd.qcut(combined['Fare'], 5, labels=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:36.345932Z","iopub.execute_input":"2022-05-24T11:24:36.346309Z","iopub.status.idle":"2022-05-24T11:24:36.365112Z","shell.execute_reply.started":"2022-05-24T11:24:36.346272Z","shell.execute_reply":"2022-05-24T11:24:36.363910Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"#### Select only coluns we will use and scale them","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0"}},{"cell_type":"code","source":"selected = ['Pclass', 'Sex', 'Age', 'Fare', 'family_size', 'family_survival']\nscaler  = StandardScaler()\nscaler.fit(combined[selected])\ncombined[selected] = scaler.transform(combined[selected])","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:36.366595Z","iopub.execute_input":"2022-05-24T11:24:36.367006Z","iopub.status.idle":"2022-05-24T11:24:36.386055Z","shell.execute_reply.started":"2022-05-24T11:24:36.366940Z","shell.execute_reply":"2022-05-24T11:24:36.385005Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"combined.to_parquet('titanic_family_survivabillity.parquet', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:36.387360Z","iopub.execute_input":"2022-05-24T11:24:36.387656Z","iopub.status.idle":"2022-05-24T11:24:36.696783Z","shell.execute_reply.started":"2022-05-24T11:24:36.387627Z","shell.execute_reply":"2022-05-24T11:24:36.695673Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"#### Now we split the sets back to train/test","metadata":{}},{"cell_type":"code","source":"train = combined.loc[combined['set'] == 'train'].drop('set', axis=1).reset_index(drop=True)\ntest = combined.loc[combined['set'] == 'test'].drop(['set', 'Survived'], axis=1).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:36.698274Z","iopub.execute_input":"2022-05-24T11:24:36.698589Z","iopub.status.idle":"2022-05-24T11:24:36.711927Z","shell.execute_reply.started":"2022-05-24T11:24:36.698558Z","shell.execute_reply":"2022-05-24T11:24:36.710859Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# 3. Algorithm\nKNN works by finding, as the name suggests, the nearest neighbor. It assumes that classes share similar properties. To compare to points, we have to see them as vectors. Each feature adds to a dimension. Would we only have a single feature it would be the numeric distance between the two points. With two or more features, we need to do something smarter. To create a single number to express the similarity (or distance) we need to agegrate all the features (or dimensions). One way is to use the Euclidean distance, which is the root of the sum of squared distances between all features. There are many other ways to agegrate the feature distances, all with their strengths and weaknesses. For this example, we will use the Euclidean distance.","metadata":{}},{"cell_type":"code","source":"def euclidean_distance(vector1, vector2):\n    return np.sqrt(np.sum((vector1 - vector2)**2))\n\n# test function\nvec1 = np.array([3, 0])\nvec2 = np.array([0, 4])\n\n# this is the 3:4:5 triangle and therefore, it should return 5 (Long live Pythagoras)\neuclidean_distance(vec1, vec2)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:36.713672Z","iopub.execute_input":"2022-05-24T11:24:36.714242Z","iopub.status.idle":"2022-05-24T11:24:36.731830Z","shell.execute_reply.started":"2022-05-24T11:24:36.714194Z","shell.execute_reply":"2022-05-24T11:24:36.730756Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"Using our distance function we will now find the closest match in our dataset, when providing a vector.","metadata":{}},{"cell_type":"code","source":"# A first implementation\ndef get_nearest_neighbor(vector, dataset, number_of_neighbors=1, ignore_cols=['Survived']):\n    distances = []\n    for ix, row in dataset.loc[:, ~dataset.columns.isin(ignore_cols)].iterrows():\n        distance = euclidean_distance(row, vector)\n        distances.append((distance, ix))\n    indices = [x[1] for x in sorted(distances, key=lambda x: x[0])]\n    neighbors = dataset.loc[indices[:number_of_neighbors]]\n    return neighbors\n\n# Another implementation using Pandas\ndef get_nearest_neighbor(vector, dataset, number_of_vectors=1, ignore_cols=['Survived'], not_count_duplicates=False):\n    ds = dataset.copy()\n    ds['distance'] = ds.loc[:, ~ds.columns.isin(ignore_cols)].apply(\n        lambda x: euclidean_distance(x, vector), axis=1)\n    if not_count_duplicates:\n        distances = sorted(ds.distance.unique())[:number_of_vectors]\n        return ds.loc[ds.distance <= max(distances)].drop('distance', axis=1)\n    return ds.sort_values('distance', ascending=True).head(number_of_vectors).drop('distance', axis=1)\n        \n# test function\ndataset = pd.DataFrame([\n    {'a': 1, 'b': 1, 'Survived': 1},\n    {'a': 2, 'b': 2, 'Survived': 1},\n    {'a': 3, 'b': 3, 'Survived': 0},\n    {'a': 4, 'b': 4, 'Survived': 0},\n    {'a': 5, 'b': 5, 'Survived': 0},\n])\nvector = pd.Series({'a': 2.5, 'b': 2.5})\n\n# should be (2,2) and (3,3) (if keeping track of duplicates)\nget_nearest_neighbor(vector, dataset)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:36.733535Z","iopub.execute_input":"2022-05-24T11:24:36.734050Z","iopub.status.idle":"2022-05-24T11:24:36.775750Z","shell.execute_reply.started":"2022-05-24T11:24:36.734007Z","shell.execute_reply":"2022-05-24T11:24:36.774758Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"Now that we have a function to list the nearest neighbors, we need to select the most dominant class of those neighbors to select as our prediction.","metadata":{}},{"cell_type":"code","source":"def predict(vector, dataset, number_of_neighbors=1, y='Survived'):\n    neighbors = get_nearest_neighbor(vector, dataset, number_of_neighbors)\n    return round(neighbors[y].mean())\n\n# test function\nprint(predict(vector, dataset))\nprint(predict(pd.Series({'a': 4.5, 'b': 4.5}), dataset))","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:36.777397Z","iopub.execute_input":"2022-05-24T11:24:36.777876Z","iopub.status.idle":"2022-05-24T11:24:36.802840Z","shell.execute_reply.started":"2022-05-24T11:24:36.777831Z","shell.execute_reply":"2022-05-24T11:24:36.801726Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# 4. Test algorithm on Titanic dataset","metadata":{}},{"cell_type":"markdown","source":"To test, we select on row from the set and use KNN to find the best candidate. Of course, we will remove that row from the dataset, or we would find a distance of zero as the identical row is in there.","metadata":{}},{"cell_type":"code","source":"def predict_dataset(dataset, number_of_neighbors=1):\n    ds = dataset.copy()\n    def predict_row(vector, dataset):\n        subset = dataset.loc[~(dataset.index==vector.name)]\n        if vector.name % 100 == 0:\n            print(vector.name)\n        return int(predict(vector, subset, number_of_neighbors))\n\n    ds['predicted'] = ds.loc[:, ds.columns.isin(selected)].apply(\n        lambda x: predict_row(x, ds), axis=1)\n    \n    return ds\n\nds = predict_dataset(train, number_of_neighbors=10)\n\nprint('Accuracy:', sum(ds['Survived'] == ds['predicted']) / len(ds))\n","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:24:36.804265Z","iopub.execute_input":"2022-05-24T11:24:36.804700Z","iopub.status.idle":"2022-05-24T11:40:20.201545Z","shell.execute_reply.started":"2022-05-24T11:24:36.804667Z","shell.execute_reply":"2022-05-24T11:40:20.200461Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"We find a accuracy of 83.5% on the training set. Lets now make our test set predictions.","metadata":{}},{"cell_type":"markdown","source":"## 5. create prediction for testset","metadata":{}},{"cell_type":"code","source":"def predict_testset(test_dataset, train_dataset, number_of_neighbors=1):\n    ds = test_dataset.copy()\n    select = selected + ['Survived']\n    \n    def predict_row(vector, dataset):\n        if vector.name % 100 == 0:\n            print(vector.name)\n        return int(predict(vector, dataset[select], number_of_neighbors))\n\n    ds['Survived'] = ds.loc[:, ds.columns.isin(selected)].apply(\n        lambda x: predict_row(x, train_dataset), axis=1)\n    \n    return ds","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:40:20.202781Z","iopub.execute_input":"2022-05-24T11:40:20.203294Z","iopub.status.idle":"2022-05-24T11:40:20.210976Z","shell.execute_reply.started":"2022-05-24T11:40:20.203254Z","shell.execute_reply":"2022-05-24T11:40:20.210104Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"final_test = predict_testset(test, train, number_of_neighbors=10)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:40:20.212066Z","iopub.execute_input":"2022-05-24T11:40:20.212518Z","iopub.status.idle":"2022-05-24T11:46:00.492059Z","shell.execute_reply.started":"2022-05-24T11:40:20.212469Z","shell.execute_reply":"2022-05-24T11:46:00.491107Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"result = final_test[['PassengerId', 'Survived']].copy()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:46:00.493716Z","iopub.execute_input":"2022-05-24T11:46:00.494508Z","iopub.status.idle":"2022-05-24T11:46:00.502196Z","shell.execute_reply.started":"2022-05-24T11:46:00.494457Z","shell.execute_reply":"2022-05-24T11:46:00.501030Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"result","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:46:00.503839Z","iopub.execute_input":"2022-05-24T11:46:00.504184Z","iopub.status.idle":"2022-05-24T11:46:00.529744Z","shell.execute_reply.started":"2022-05-24T11:46:00.504153Z","shell.execute_reply":"2022-05-24T11:46:00.528391Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"result.to_csv('results.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T11:46:00.531268Z","iopub.execute_input":"2022-05-24T11:46:00.531880Z","iopub.status.idle":"2022-05-24T11:46:00.976297Z","shell.execute_reply.started":"2022-05-24T11:46:00.531836Z","shell.execute_reply":"2022-05-24T11:46:00.975237Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}